{\let\clearpage\relax \chapter[Annotated Corpus]{Corpus of Annotated Conversations\label{cpt: method annotated corpus}}}

We apply our improved \gls{da} classification and topic extraction methods to 18,000 conversations selected from the Spotify podcast corpus\cite{clifton-2020100000}. By annotating the transcript with the extracted linguistic features, we create a corpus that can be used for the linguistic research we originally intended to do.

\section{Selection of Podcasts}
We select only podcasts with more than one speaker and of a minimum length of 100 \glspl{utterance}. The sample of 18,000 podcasts matching this criterion is selected randomly.

\section{Computational Optimisation}
We optimise our annotation of transcripts by caching language \glspl{model} and intermediate results such as inter-\gls{keyphrase} similarity in our topic extraction algorithm GEEK.
We make the processing of transcripts multi-threaded and split the work-load between the graphical processing unit (GPU) and the central processing unit (CPU), because the graphical memory available for the GPU is limited and the cached \glspl{model} are large. This allows us to process three transcripts at once, at an average rate of $\approx 0.2$ transcripts/second leading to a total processing time of $\approx 25$ hours.

We are confident our implementation can not be optimised much further because more than $96\%$ of computation time is used by the libraries we use (deep learning library keras\cite{chollet2015keras} for \gls{da} classification and \gls{nlp} library flairNLP\cite{flairNLP}), and our system uses all available memory to store essential components (and thus can not be parallelised further).

\section{Access to Corpus}

As the Spotify podcast data-set requires approval for access, we can unfortunately only provide our annotated corpus to researchers who have already been approved for said data-set. \newline
