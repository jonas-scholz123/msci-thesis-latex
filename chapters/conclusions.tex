\chapter{Conclusions}
We aimed to evaluate a wide range of natural language processing techniques for \gls{da} and topic analysis within the context of conversations and to improve them and we succeeded in doing so.
\subsubsection{State of the Art Dialogue Act Classification}
    For \gls{da} classification, we select a 2017 \gls{model} by Kumar et al., re-implement it within a newer python framework, fix an important bug and modernise components such as the word \glspl{embedding} and recurrent neural network architecture, improving it from an accuracy of $79.2 \pm 0.3\%$ in the \gls{swda} Corpus to an accuracy of $84.6 \pm 0.3\%$, beating the previous state of the art accuracy of $83.1$ as well as the inter-annotator agreement accuracy of $84\%$ between the annotators who created the corpus.

\subsubsection{State of the Art Conversation Topic Modelling}
    Within the area of topic modelling, specifically when applying it to conversations, research is much less active than within \gls{da} classification, and no standard corpora exist for evaluation. Therefore, we hand-annotated 4 podcast transcript excerpts and evaluated \glspl{model} against those. We evaluated it and other methods, such as \gls{utterance} \gls{embedding} based clustering, via a minimum-cut graph following the work of Malioutov et al., and other unsupervised clustering methods, but qualitatively achieve such underwhelming results that we do not attempt a quantitative evaluation. The previous state of the art topic-\gls{model}, BayesSeg, performs better, but still does not achieve satisfactory performance, a \textit{windowDiff} penalty score of $0.39 \pm 0.06$ for topic segmentation.
    By identifying the key problem in all these approaches, the fact that many words in conversations are unrelated to the topic and therefore dilute seperation of dissimilar topics, we develop our own method: a graph of embedded extracted \glspl{keyphrase} (GEEK).
    GEEK follows a modified version of the TopicRank approach by Bougouin et al. to extract key-words and multi-word phrases that are likely to represent topics and then uses word \glspl{embedding} of these key-words to identify semantically cohesive sections as topics with their keywords as topic labels. We find that \gls{geek} is significantly more robust against weak key-word candidates than TopicRank by using semantically similar words to determine importance of candidates, not just repetitions of the exact candidate, and by filtering a list of 89 manually determined ``false flag" key-word candidates. We also improve the overall selection of \glspl{keyphrase} over TopicRank by employing \gls{ner} to extract named entities (such as ``Donald Trump" or ``CIA"), which often indicate topics. Quantitatively, GEEK significantly improves upon the state of the art topic segmentation by BayesSeg, achieving the much lower \textit{windowDiff} penalty score of $\mathbf{0.22 \pm 0.04}$. We emphasize that this score is likely somewhat biased because we both \textit{created} the segmentation algorithm and annotated the dataset with which it is \textit{evaluated}, both of which are subject to our own biases as to what constitutes a topic and what constitutes a change of topic. However, we are confident that \gls{geek} would still outperform the previous state of the art in an independently annotated dataset and propose the creation of such a dataset as a standardised metric to encourage and legitimise future work in this area.

\subsubsection{Creation of a Public Corpus of Annotated Podcast Transcripts}
    We parallelise and optimise our analysis methods to annotate a large selection of 18000 podcasts from the Spotify podcast corpus\cite{clifton-2020100000} with \glspl{da}, keywords and topics. This corpus can be used to study a wide range of linguistic questions, such as \dots. Upon request, we make it available to any researchers that have also been granted access to the Spotify podcast corpus.
\glsresetall

\newpage
