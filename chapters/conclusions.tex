\chapter{Conclusions}
We aimed to evaluate a wide range of natural language processing techniques for \gls{da} and topic analysis within the context of conversations and to improve them and we succeeded in doing so.
\subsubsection{State of the Art Dialogue Act Classification}
    For \gls{da} classification, we select a \gls{model} developed within IBM Research by Kumar et al.\cite{kumar2017dialogue}, re-implement it within a newer python framework, fix an important bug and modernise components such as the word \glspl{embedding} and recurrent neural network architecture, improving it from an accuracy of $79.2 \pm 0.3\%$ in the \gls{swda} Corpus to an accuracy of $84.6 \pm 0.3\%$, beating the previous state of the art accuracy of $83.1$ as well as the inter-annotator agreement accuracy of $84\%$ between the annotators who created the corpus.

\subsubsection{State of the Art Conversation Topic Modelling}
    Within the area of topic modelling, specifically when applying it to conversations, research is much less active than within \gls{da} classification, and no standard corpora exist for evaluation. Therefore, we hand-annotated 4 podcast transcript excerpts and evaluated \glspl{model} against those. We evaluated existing segmentation methods, including \gls{utterance} \gls{embedding} based clustering and the previous state of the art topic-\gls{model}, BayesSeg as well as the topic-labelling method TopicRank.
    
    After identifying key-weaknesses of these approaches when identified to conversations, we develop a novel method, the \gls{geek} algorithm.
    %performs better, but still does not achieve satisfactory performance, a \textit{windowDiff} penalty score of $0.39 \pm 0.06$ for topic segmentation.
    %By identifying the key problem in the approaches we analyse, the fact that many words in conversations are unrelated to the topic and therefore dilute seperation of dissimilar topics, we develop our own method: a \gls{geek}.
    \gls{geek} follows a modified version of the TopicRank approach to extract \glspl{keyphrase} that are likely to represent topics and then uses word \glspl{embedding} of these \glspl{keyphrase} to identify semantically cohesive sections as topics with their keywords as topic labels.
    %We ensure that \gls{geek} is significantly more robust against weak \gls{keyphrase} candidates than TopicRank by using semantically similar words to determine importance of candidates, not just repetitions of the exact candidate, and by filtering a list of 89 manually determined ``false flag" \gls{keyphrase} candidates. We also improve the overall selection of \glspl{keyphrase} over TopicRank by employing \gls{ner} to extract named entities (such as ``Donald Trump" or ``CIA"), which often indicate topics. 
    
    Quantitatively, \gls{geek} significantly improves upon the state of the art topic segmentation achieving a \textit{windowDiff} penalty score of \mathbf{$0.22 \pm 0.04$} (compared to BayesSeg's \textit{windowDiff} score of $0.39 \pm 0.06$). 
    
    We emphasize that this score is likely somewhat biased because we both \textit{created} the segmentation algorithm and annotated the dataset with which it is \textit{evaluated} (both of which are subject to our own biases as to what constitutes a topic and what constitutes a change of topic). However, we are confident that \gls{geek} would still outperform the previous state of the art in an independently annotated dataset and propose the creation of such a dataset as a standardised metric to encourage and legitimise future work in this area.
    

\subsubsection{Creation of a Public Corpus of Annotated Podcast Transcripts}
    Finally, we parallelise and optimise our analysis methods to annotate a large selection of 18000 podcasts from the Spotify podcast corpus\cite{clifton-2020100000} with \glspl{da}, keywords and topics. This corpus can be used for large-scale linguistic study. Upon request, we make it available to any researchers that have also been granted access to the Spotify podcast corpus.
    
    Overall, we believe that our algorithms can find wide application for example within pure linguistic research, within smart assistants such as Amazon's Alexa, or commercially, by identifying what conversation types lead to successful meetings.
    
\glsresetall

\newpage
